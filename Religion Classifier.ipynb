{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buddhism', 'christianity', 'hinduism', 'islam', 'non-religious']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sklearn.datasets\n",
    "rel_train = sklearn.datasets.load_files('datasets/rel_train/')\n",
    "# Name of categories\n",
    "rel_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 35327)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(decode_error=u'ignore')\n",
    "X_train_counts = count_vect.fit_transform(rel_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 35327)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training a classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, rel_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),])\n",
    "text_clf = text_clf.fit(rel_train.data, rel_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate: Predict accuracy\n",
    "import numpy as np\n",
    "rel_test = sklearn.datasets.load_files('datasets/rel_test/')\n",
    "predicted = text_clf.predict(rel_test.data)\n",
    "np.mean(predicted == rel_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78125"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([('vect', CountVectorizer(decode_error='ignore')),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=1e-3, n_iter=5, random_state=42))\n",
    "                     ])\n",
    "text_clf = text_clf.fit(rel_train.data, rel_train.target)\n",
    "predicted = text_clf.predict(rel_test.data)\n",
    "np.mean(predicted == rel_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     buddhism       0.84      0.81      0.83        32\n",
      " christianity       0.53      0.94      0.67        32\n",
      "     hinduism       1.00      0.34      0.51        32\n",
      "        islam       0.97      0.97      0.97        32\n",
      "non-religious       0.93      0.84      0.89        32\n",
      "\n",
      "  avg / total       0.85      0.78      0.77       160\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[26,  6,  0,  0,  0],\n",
       "       [ 0, 30,  0,  0,  2],\n",
       "       [ 5, 15, 11,  1,  0],\n",
       "       [ 0,  1,  0, 31,  0],\n",
       "       [ 0,  5,  0,  0, 27]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(rel_test.target, predicted, \n",
    "                                    target_names=rel_test.target_names))\n",
    "metrics.confusion_matrix(rel_test.target, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hinduism': 11, 'buddhism': 31, 'islam': 32, 'non-religious': 29, 'christianity': 57}\n"
     ]
    }
   ],
   "source": [
    "# Testing test sets\n",
    "result = {'buddhism': 0, 'christianity': 0,\n",
    "         'hinduism': 0, 'islam': 0, 'non-religious': 0}\n",
    "for instance, category in zip(rel_train.data, predicted):\n",
    "    result[rel_train.target_names[category]] += 1\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in bible 677\n",
      "Result of bible\n",
      "('hinduism', 0.0)\n",
      "('buddhism', 4.726735598227474)\n",
      "('islam', 4.726735598227474)\n",
      "('non-religious', 3.3973412112259975)\n",
      "('christianity', 87.14918759231905)\n"
     ]
    }
   ],
   "source": [
    "# Testing bible\n",
    "path = 'datasets/bible/'\n",
    "root = '/Users/Sheon/nlp/datasets/bible/'\n",
    "bible = []\n",
    "for filename in os.listdir(path):\n",
    "    f = open(os.path.join(root, filename), 'r')\n",
    "    bible.append(f.read())\n",
    "predicted = text_clf.predict(bible)\n",
    "result = {'buddhism': 0, 'christianity': 0,\n",
    "         'hinduism': 0, 'islam': 0, 'non-religious': 0}\n",
    "count = 0\n",
    "for instance, category in zip(bible, predicted):\n",
    "    result[rel_train.target_names[category]] += 1\n",
    "    count += 1\n",
    "print \"Number of instances in \" + filename[:-3] + \" \" + str(count)\n",
    "print \"Result of \" + filename[:-3]\n",
    "for key, value in result.items():\n",
    "    result[key] = value / float(count) * 100\n",
    "    print (key, result[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in democrats_nomination_speeches 93\n",
      "Result of democrats_nomination_speeches\n",
      "('hinduism', 0.0)\n",
      "('buddhism', 2.1505376344086025)\n",
      "('islam', 12.903225806451612)\n",
      "('non-religious', 40.86021505376344)\n",
      "('christianity', 44.086021505376344)\n"
     ]
    }
   ],
   "source": [
    "# Testing democrats\n",
    "path = 'input/nomination_democrats/'\n",
    "root = '/Users/Sheon/nlp/input/nomination_democrats/'\n",
    "democrats_nomination = []\n",
    "for filename in os.listdir(path):\n",
    "    f = open(os.path.join(root, filename), 'r')\n",
    "    democrats_nomination.append(f.read())\n",
    "predicted = text_clf.predict(democrats_nomination)\n",
    "result = {'buddhism': 0, 'christianity': 0,\n",
    "         'hinduism': 0, 'islam': 0, 'non-religious': 0}\n",
    "count = 0\n",
    "for instance, category in zip(democrats_nomination, predicted):\n",
    "    result[rel_train.target_names[category]] += 1\n",
    "    count += 1\n",
    "print \"Number of instances in \" + filename[:-3] + \" \" + str(count)\n",
    "print \"Result of \" + filename[:-3]\n",
    "for key, value in result.items():\n",
    "    result[key] = value / float(count) * 100\n",
    "    print (key, result[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in nomi_repub 121\n",
      "Result of nomi_repub\n",
      "('hinduism', 0.0)\n",
      "('buddhism', 0.0)\n",
      "('islam', 28.92561983471074)\n",
      "('non-religious', 35.53719008264463)\n",
      "('christianity', 35.53719008264463)\n"
     ]
    }
   ],
   "source": [
    "# Testing republicans\n",
    "path = 'input/nomination_republican//'\n",
    "root = '/Users/Sheon/nlp/input/nomination_republican/'\n",
    "republican_nomination = []\n",
    "for filename in os.listdir(path):\n",
    "    f = open(os.path.join(root, filename), 'r')\n",
    "    republican_nomination.append(f.read())\n",
    "predicted = text_clf.predict(republican_nomination)\n",
    "result = {'buddhism': 0, 'christianity': 0,\n",
    "         'hinduism': 0, 'islam': 0, 'non-religious': 0}\n",
    "count = 0\n",
    "for instance, category in zip(republican_nomination, predicted):\n",
    "    result[rel_train.target_names[category]] += 1\n",
    "    count += 1\n",
    "print \"Number of instances in \" + filename[:-3] + \" \" + str(count)\n",
    "print \"Result of \" + filename[:-3]\n",
    "for key, value in result.items():\n",
    "    result[key] = value / float(count) * 100\n",
    "    print (key, result[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in trump 101\n",
      "Result of trump\n",
      "('hinduism', 0.0)\n",
      "('buddhism', 4.9504950495049505)\n",
      "('islam', 30.693069306930692)\n",
      "('non-religious', 5.9405940594059405)\n",
      "('christianity', 58.415841584158414)\n"
     ]
    }
   ],
   "source": [
    "# Testing trump\n",
    "path = 'input/trump_speeches/'\n",
    "root = '/Users/Sheon/nlp/input/trump_speeches/'\n",
    "trump_speeches = []\n",
    "for filename in os.listdir(path):\n",
    "    f = open(os.path.join(root, filename), 'r')\n",
    "    trump_speeches.append(f.read())\n",
    "predicted = text_clf.predict(trump_speeches)\n",
    "result = {'buddhism': 0, 'christianity': 0,\n",
    "         'hinduism': 0, 'islam': 0, 'non-religious': 0}\n",
    "count = 0\n",
    "for instance, category in zip(trump_speeches, predicted):\n",
    "    result[rel_train.target_names[category]] += 1\n",
    "    count += 1\n",
    "print \"Number of instances in \" + filename[:-3] + \" \" + str(count)\n",
    "print \"Result of \" + filename[:-3]\n",
    "for key, value in result.items():\n",
    "    result[key] = value / float(count) * 100\n",
    "    print (key, result[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carter\n",
      "Clinton\n",
      "Coolidge\n",
      "Eisenhower\n",
      "FDR\n",
      "Ford\n",
      "Harding\n",
      "Hbush\n",
      "Hoover\n",
      "Johnson\n",
      "Kennedy\n",
      "Nixon\n",
      "Obama\n",
      "Reagan\n",
      "Taft\n",
      "TDR\n",
      "Truman\n",
      "Wbush\n",
      "WWS\n"
     ]
    }
   ],
   "source": [
    "# testing democrats nomination\n",
    "path = '/Users/Sheon/nlp/input/presidents/'\n",
    "target = open('/Users/Sheon/nlp/input/presidents/sou_rel_result.json', 'w')\n",
    "\n",
    "for dirname in os.listdir(path):\n",
    "    if (dirname == \".DS_Store\" or dirname == \"sou_rel_result.json\" or dirname == 'sou_result.json'): continue \n",
    "    pathPres = path + dirname\n",
    "    president = []\n",
    "    for filename in os.listdir(pathPres):\n",
    "        f = open(os.path.join(pathPres, filename), 'r')\n",
    "        president.append(f.read())\n",
    "    predicted = text_clf.predict(president)\n",
    "    \n",
    "    result = {\"buddhism\": 0, \"christianity\": 0, \"hinduism\": 0, 'islam': 0, 'non-religious': 0}\n",
    "    count = 0\n",
    "    for instance, category in zip(president, predicted):\n",
    "        result[rel_train.target_names[category]] += 1\n",
    "        count += 1\n",
    "    print str(dirname)\n",
    "    # print result\n",
    "    # print \"Count: \" + str(count)\n",
    "    for key, value in result.items():\n",
    "        result[key] = value / float(count) * 100\n",
    "        #print (key, result[key])\n",
    "    target.write(str(result))\n",
    "    target.write(', ')\n",
    "    # print result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adams\n",
      "J.Q.Adams\n",
      "Jackson\n",
      "Jefferson\n",
      "Madison\n",
      "Monroe\n",
      "Washington\n"
     ]
    }
   ],
   "source": [
    "# testing democrats nomination\n",
    "path = '/Users/Sheon/nlp/input/old_presidents/'\n",
    "target = open('/Users/Sheon/nlp/input/old_presidents/sou_rel_result.json', 'w')\n",
    "\n",
    "for dirname in os.listdir(path):\n",
    "    if (dirname == \".DS_Store\" or dirname == \"sou_rel_result.json\" or dirname == 'sou_result.json'): continue \n",
    "    pathPres = path + dirname\n",
    "    president = []\n",
    "    for filename in os.listdir(pathPres):\n",
    "        f = open(os.path.join(pathPres, filename), 'r')\n",
    "        president.append(f.read())\n",
    "    predicted = text_clf.predict(president)\n",
    "    result = {'buddhism': 0, 'christianity': 0, 'hinduism': 0, 'islam': 0, 'non-religious': 0}\n",
    "    count = 0\n",
    "    for instance, category in zip(president, predicted):\n",
    "        result[rel_train.target_names[category]] += 1\n",
    "        count += 1\n",
    "    print str(dirname)\n",
    "    # print result\n",
    "    # print \"Count: \" + str(count)\n",
    "    for key, value in result.items():\n",
    "        result[key] = value / float(count) * 100\n",
    "        #print (key, result[key])\n",
    "    target.write(str(result))\n",
    "    target.write(', ')\n",
    "    # print result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hinduism': 0, 'buddhism': 5, 'islam': 31, 'non-religious': 6, 'christianity': 59}\n",
      "Count: 101\n",
      "('hinduism', 0.0)\n",
      "('buddhism', 4.9504950495049505)\n",
      "('islam', 30.693069306930692)\n",
      "('non-religious', 5.9405940594059405)\n",
      "('christianity', 58.415841584158414)\n"
     ]
    }
   ],
   "source": [
    "# testing trump nomination\n",
    "path = 'input/trump_speeches/'\n",
    "root = '/Users/Sheon/nlp/input/trump_speeches/'\n",
    "trump_speeches = []\n",
    "for filename in os.listdir(path):\n",
    "    f = open(os.path.join(root, filename), 'r')\n",
    "    trump_speeches.append(f.read())\n",
    "predicted = text_clf.predict(trump_speeches)\n",
    "\n",
    "result = {'buddhism': 0, 'christianity': 0, 'hinduism': 0, 'islam': 0, 'non-religious': 0}\n",
    "\n",
    "count = 0\n",
    "for instance, category in zip(trump_speeches, predicted):\n",
    "    result[rel_train.target_names[category]] += 1\n",
    "    count += 1\n",
    "print result\n",
    "print \"Count: \" + str(count)\n",
    "for key, value in result.items():\n",
    "    result[key] = value / float(count) * 100\n",
    "    print (key, result[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hinduism': 0, 'buddhism': 1, 'islam': 1, 'non-religious': 8, 'christianity': 91}\n",
      "Count: 101\n",
      "('hinduism', 0.0)\n",
      "('buddhism', 0.9900990099009901)\n",
      "('islam', 0.9900990099009901)\n",
      "('non-religious', 7.920792079207921)\n",
      "('christianity', 90.0990099009901)\n"
     ]
    }
   ],
   "source": [
    "# testing hillary nomination\n",
    "path = 'input/hillary/'\n",
    "root = '/Users/Sheon/nlp/input/hillary/'\n",
    "hillary = []\n",
    "for filename in os.listdir(path):\n",
    "    f = open(os.path.join(root, filename), 'r')\n",
    "    hillary.append(f.read())\n",
    "predicted = text_clf.predict(hillary)\n",
    "\n",
    "result = {'buddhism': 0, 'christianity': 0, 'hinduism': 0, 'islam': 0, 'non-religious': 0}\n",
    "\n",
    "count = 0\n",
    "for instance, category in zip(hillary, predicted):\n",
    "    result[rel_train.target_names[category]] += 1\n",
    "    count += 1\n",
    "print result\n",
    "print \"Count: \" + str(count)\n",
    "for key, value in result.items():\n",
    "    result[key] = value / float(count) * 100\n",
    "    print (key, result[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hinduism': 0, 'buddhism': 2, 'islam': 12, 'non-religious': 38, 'christianity': 41}\n",
      "Count: 93\n",
      "('hinduism', 0.0)\n",
      "('buddhism', 2.1505376344086025)\n",
      "('islam', 12.903225806451612)\n",
      "('non-religious', 40.86021505376344)\n",
      "('christianity', 44.086021505376344)\n"
     ]
    }
   ],
   "source": [
    "# testing democrats nomination\n",
    "path = 'input/nomination_democrats/'\n",
    "root = '/Users/Sheon/nlp/input/nomination_democrats/'\n",
    "democrats_nomination = []\n",
    "for filename in os.listdir(path):\n",
    "    f = open(os.path.join(root, filename), 'r')\n",
    "    democrats_nomination.append(f.read())\n",
    "predicted = text_clf.predict(democrats_nomination)\n",
    "\n",
    "result = {'buddhism': 0, 'christianity': 0, 'hinduism': 0, 'islam': 0, 'non-religious': 0}\n",
    "\n",
    "count = 0\n",
    "for instance, category in zip(democrats_nomination, predicted):\n",
    "    result[rel_train.target_names[category]] += 1\n",
    "    count += 1\n",
    "print result\n",
    "print \"Count: \" + str(count)\n",
    "for key, value in result.items():\n",
    "    result[key] = value / float(count) * 100\n",
    "    print (key, result[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hinduism': 0, 'buddhism': 0, 'islam': 35, 'non-religious': 43, 'christianity': 43}\n",
      "Count: 121\n",
      "('hinduism', 0.0)\n",
      "('buddhism', 0.0)\n",
      "('islam', 28.92561983471074)\n",
      "('non-religious', 35.53719008264463)\n",
      "('christianity', 35.53719008264463)\n"
     ]
    }
   ],
   "source": [
    "# testing republican nomination\n",
    "path = 'input/nomination_republican//'\n",
    "root = '/Users/Sheon/nlp/input/nomination_republican/'\n",
    "republican_nomination = []\n",
    "for filename in os.listdir(path):\n",
    "    f = open(os.path.join(root, filename), 'r')\n",
    "    republican_nomination.append(f.read())\n",
    "predicted = text_clf.predict(republican_nomination)\n",
    "\n",
    "result = {'buddhism': 0, 'christianity': 0, 'hinduism': 0, 'islam': 0, 'non-religious': 0}\n",
    "\n",
    "count = 0\n",
    "for instance, category in zip(republican_nomination, predicted):\n",
    "    result[rel_train.target_names[category]] += 1\n",
    "    count += 1\n",
    "print result\n",
    "print \"Count: \" + str(count)\n",
    "for key, value in result.items():\n",
    "    result[key] = value / float(count) * 100\n",
    "    print (key, result[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
